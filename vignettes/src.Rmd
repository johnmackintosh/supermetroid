---
title: "src"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{src}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  error=TRUE,
  warning=FALSE,
  eval=TRUE,
  fig.width = 8,
  fig.height = 6
)
```


```{r setup, message=FALSE, eval=TRUE}
# most chunks in this vignette are not evaluated because I'm not sure how to
# save nested dictionaries yet, and calling the api borks in knitting but
# not in console.

# load R analysis package
library(supermetroid)

# other tools
library(tidyverse)
# so R can talk to Python
library(reticulate)
# for html tables
library(gt)

```

# speedrun.com

Speedrun.com is (according to the the two speed runners I've spoken to) the 
canonical leaderboard for speed runners on the internet. Because it is
believed to be the most complete set (I'd like to check this with data) of 
speed runs, the canonical ranking of players amongst the community is their
Speedrun.com ranking.

```{r eval=TRUE}
data(src_df)

all_run_raincloud(src_run_df)

```

The code below is how these data were extracted and cleaned for the 
visualisation above.

```{r eval=TRUE}
src_df %>% head() %>% gt()

```


## api

There is a Python module for accessing speedrun.com .

```{python}
# load Python modules 
import srcomapi, srcomapi.datatypes as dt
import pandas as pd # for wrangling into df
import time
import json
import math

# Tak, Anthony :)
import pprint
pp = pprint.PrettyPrinter(indent=4)


```


### Get data

```{python, eval=FALSE}
# this chunk is only evaluated when data is updated

# this chunk code copied from
# https://github.com/blha303/srcomapi

# call api
src_api = srcomapi.SpeedrunCom(); src_api.debug = 1

# It's recommended to cache the game ID and use it for future requests.
# Data is cached for the current session by classname/id so future
# requests for the same game are instantaneous.

src_api.search(srcomapi.datatypes.Game, {"name": "super metroid"})

# can we add a historical == true to this?
game = _[0]

srcomapi_runs = {}
for category in game.categories:
  if not category.name in srcomapi_runs:
    srcomapi_runs[category.name] = {}
  if category.type == 'per-level':
    for level in game.levels:
      srcomapi_runs[category.name][level.name] = dt.Leaderboard(src_api, data=src_api.get("leaderboards/{}/level/{}/{}?embed=variables".format(game.id, level.id, category.id)))
  else:
    srcomapi_runs[category.name] = dt.Leaderboard(src_api, data=src_api.get("leaderboards/{}/category/{}?embed=variables".format(game.id, category.id)))


### 100% Super Metroid leaderboard
src_leaderboard = srcomapi_runs['100%']



# list of dictionaries
type(src_leaderboard)

# Only nested object seems to be runs
src_leaderboard.keys()

# Don't know what this is, is it useful?
# generator object DataType
src_leaderboard.variables 

type(src_leaderboard.runs)
type(src_leaderboard.runs[0])
src_leaderboard.runs[0]['run'].data

# convert the run objects to dictionaries
src_runs = [src_leaderboard.runs[x]['run'].data for x in range(len(src_leaderboard.runs))]


```

### Get runs

```{python}


# list of 
type(src_runs)
# dictionaries
type(src_runs[1])

# extracting specific values
src_runs[0].keys()

# rank
src_leaderboard.runs[0]['place']

# run as a nested dictionary
src_runs[0].keys()

# Inspect bits we want to extract
src_runs[5]['id']
src_runs[5]['times']
src_runs[5]['date']

for x in range(len(src_runs)):
  print(src_runs[x]['players'][0]['id'])

```


## Run dataframe

src_run_df | description | from
- | - | - 
date | timestamp of run upload | `runs[index]['run']['date']`
*run_id* | unique identifier of run | `runs[index]['run']['date']`
run_time | total time of run in s or ms | `runs[index]['run']['times']['realtime_t']`
*player_id* | unique identifier of player | player id == run id, debug extraction
rank | rank, empty if historical, currently don't have historical obs | `src_runs[x]['place']`
 
```{python}

n_obs = len(src_runs)

# how to get splits? [src_runs][x]['run']['splits']

# get a list of players
src_players = [pd.DataFrame(
  src_runs[x]['players']) for x in range(len(src_runs))]

# check length of run-player is same
len(src_players)

# i think these are all single-depth dicts, and can be flattened
pp.pprint(src_players[0:3])

# concatenate players into df
src_player_df = pd.concat(src_players).rename(columns={
  'uri':'uri_player',
  'id':'src_id',
  'rel':'src_user_guest'
})

# create api call
src_player_df["api_call"] = src_player_df[
  'src_id'].fillna(src_player_df['name'])

# ugh couldn't figure out how to lambda that ifelse
src_player_df = src_player_df.drop(columns = ['src_id', 'name'])

# take a look
src_player_df.head()

# check number of records should match runs
src_player_df.shape[0]


# extract elements with list comprehension (new tool for me)
src_run_df = pd.DataFrame({
  # need to inspect what happens to historical ranking
  'rank' : [src_leaderboard.runs[x]['place'] for x in range(n_obs)], 
  't_human' : [src_runs[x]['times']['primary'] 
    for x in range(n_obs)],
  'date' : [src_runs[x]['date'] for x in range(n_obs)],
  't_s' : [src_runs[x]['times']['realtime_t'] 
    for x in range(n_obs)],
  'run_id' : [src_runs[x]['id'] for x in range(n_obs)]
})

# check that run-players and runs have same length
src_player_df.shape[0] == src_run_df.shape[0]

src_run_runners_df = pd.concat([src_run_df.reset_index(drop = True), src_player_df.reset_index(drop = True)], axis=1)

# check we still have the same number of runs
# should be one row per run
len(src_leaderboard.runs) == src_run_runners_df.shape[0]

# inspect runs dataframe
src_run_runners_df.head()
src_run_runners_df.shape
src_run_runners_df.columns

```

## Player data

layer_df | description | srcomapi 
- | - | 
*player_id* | unique identifier of player 
player_handle | human-readable **unique** tag | api.get_user -> user.name
location | geographic location of player | api.get_user -> user.location

```{python}
# this loop fails because not all ids are valid


# get a list of player records for each valid player id
src_location = []
src_name = []

player = src_run_runners_df.api_call[7]

# well this turned into something horrible, despite my best efforts
# but I think it works

for player in list(src_run_runners_df.api_call):
  print("loop index")
  print(len(src_location))
  print(len(src_name))
  print(player)
  try:
    user = src_api.get_user(player)
    src_name.append(user.name)
    try: 
      src_location.append(user.location['country']['names']['international'])
    except: 
      src_location.append("no record")
  except:
    try: 
      src_api.search(srcomapi.datatypes.Player, {'name': player})
      api_player = _[0]
      src_location.append(api_player.location)
      src_name.append(player)
    except:
      src_location.append("no record")
      src_name.append(player)
  time.sleep(0.5)

src_run_runners_df.shape[0]  
len(src_location)
len(src_name)
print(src_location[0:9])
print(src_name[0:9])

# do we have the correct number of players? (repeats expected, 1/run)



```

```{python}
src_raw_df = src_run_runners_df.assign(
  player_name = src_name,
  country = src_location
)

src_raw_df.shape
src_raw_df.tail()
src_raw_df.head()

```




```{r}
# bring it over into sweet, sweet easier R
src_all_obs_df <- py$src_raw_df %>% 
  select(rank, 
         player_name, 
         date, 
         t_human, 
         country, 
         contains("id"),
         everything()) 

src_df %>% head()

```


```{r eval=FALSE}
usethis::use_data(src_df, overwrite=TRUE)

```


## Visualise runs

Now we have the data from speedrun.com leaderboard, we can plot the distribution of runs. 

```{r}
# get the data from python into R

all_run_raincloud(src_df_all_obs)


```

We have a handful of 0 entries and some > 3 hours. 

```{r}
# how many runs are really low?
src_df_all_obs %>% 
  filter(t_s < 4000 | t_s > 3 * 60 * 60)

```

The 0 entries are run times where `gametime` was captured, but `realtime` was not by the tool the player used to record the run. Our analyses are on `realtime`, so we will exclude these observations. 

We are also interest in comparing _speed runners_, as opposed to those logging playing through the game, which takes some hours. 

```{r}
(prop_greater_3hrs <- sum(src_df_all_obs$t_s > 3 * 60 * 60) / 
   nrow(src_df_all_obs))

```

Since only {r round(prop_greater_3hrs, 2) * 100}% of runs are greater than 3 hours, these are negligible, and arguably not _speed_ runs. We will define a Super Metroid speed run, for this analysis, to be a Super Metroid 100% run that takes under 3 hours. 

## Raincloud

```{r}
src_df_all_obs %>%
  filter(
    # remove 0 length runs
    t_s > 0, 
    # exclude runs > 3 hours
    t_s < 3 * 60 * 60) %>%  
  all_run_raincloud()

```


## Write run data from speedrun.com to supermetroid

```{r eval=FALSE}
# this chunk is evaluated when data is updated
src_df <- 
  src_df_all_obs %>% 
  # filter runs to less than 3 hours, and weird 0 length records
  # we won't consider these speed runs
  filter(t_s > 0, t_s < 3 * 60 * 60) %>% 
  mutate(
    rank = as.integer(rank),
    player_name = as.character(player_name),
    date = ymd(date),
    country = as.character(location)
  )

head(src_df)

```


